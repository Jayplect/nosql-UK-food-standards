## Overview
The UK Food Standards Agency evaluates various establishments across the United Kingdom, and gives them a food hygiene rating. In this project, I evaluated some of their ratings data which might be useful to journalists and food critics to decide where to focus future articles. This project implements CRUD operations, which are commonly used in database systems and APIs to manage data. CRUD stands for Create, Read, Update, and Delete, representing the basic operations performed on data. I utilized the CRUD concept to create, view, modify and delete data from the database with the help of PyMongo.

<p align="center">
 
 <img  width="350" src =https://github.com/Jayplect/nosql-challenge/assets/107348074/caf307b5-7dd0-4bf5-936d-fbdc860445bb>
 
</p>

## Technologies/Libraries
The following technologies/libraries are used in this project:

<p >
 <img  width="300" src =https://github.com/Jayplect/nosql-challenge/assets/107348074/72ec540f-c313-46a3-b5ad-1c3c965cd0ad>

 <img  width="200" src = https://user-images.githubusercontent.com/107348074/236379825-80dc02bc-46c1-46fa-9634-dc28cdcb5704.png>
</p>

## Project Steps
### Part 1: Database and Jupyter Notebook Set Up

- CRUD Operations

> Create
To begin, I imported the data from my Terminal.The <database>, <collection> and <path> represent the any specified database name, collection name and relative path of the data file. 

 ! mongoimport --type json -d <database> -c <collection> --drop --jsonArray <path>
 
To access the database I `Created` an instance of the Mongo Client using a default port of 27017. The server then processed the request and returned the resource. To confirm that the instance was returned, I used `mongo.list_database_names()` to list the representation of the created resource (in this case the databases).

> Read

I retrieved a list of all collections associated with a database using `db.collections.find_one()`. The server will respond with a list of all available collections.

> Update

An exciting new halal restaurant ("Penang Flavours") that just opened in Greenwich, but hasn't been rated yet. I inserted this new restaurant (i.e., {new_dict}) into the collection using `insert_one` function.  However, to update specific fields, I made a PUT request using PyMongo `update_one()` function to the resource. The {id} represents the unique identifier of the resource to be updated while the {dict} represent the new updates. The server will then process the request and update the resource with the provided id. The response included a representation of the updated resource in an object form which I iterated upon.
 
         #insert a new dictionary
         collection.insert_one({new_dict})

         #update field
         collection.update_one({id},{$set:{dict}})

> Delete

To demostrate this operation, I assumed that most Journalists and food critics may not be interested in any establishments within the Dover Local Authority from the database. So I checked how many documents contained the Dover Local Authority. Then, made a delete request to the resource using the {_id} endpoint, where {id} represents the unique identifier of the resource to be deleted.
         
         #delete fields
         collection.delete_many({id})

Conclusion
This readme provided an overview of the CRUD operations implemented in this project. By utilizing the specified endpoints, you can create, read, update, and delete resources as per your requirements. Refer to the <a href="https://github.com/Jayplect/nosql-challenge/tree/main">main page</a> to explore the codes and for detailed information about the request and response structures.



## Project Steps
### Part 1: Database and Jupyter Notebook Set Up

 
 This field also includes non-numeric values such as 'Pass', where 'Pass' means that the establishment passed their inspection but isn't given a number rating. We will coerce non-numeric values to nulls during the database setup before converting ratings to integers.


### Step 2: Summary Statistics 

### Step 2: Visualizations
-
## Summary of Results 

## References
Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.
